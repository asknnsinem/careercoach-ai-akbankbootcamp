import os
import json
import pandas as pd
from dotenv import load_dotenv
from google import generativeai as genai
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer

# ---------------------------------------------------------
# ğŸ”¹ Ortam deÄŸiÅŸkenlerini yÃ¼kle
# ---------------------------------------------------------
load_dotenv()
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

# ---------------------------------------------------------
# ğŸ”¹ Ã‡eviri modeli (TÃ¼rkÃ§e â†’ Ä°ngilizce)
# ---------------------------------------------------------
model_name = "facebook/m2m100_418M"
tokenizer = M2M100Tokenizer.from_pretrained(model_name)
model = M2M100ForConditionalGeneration.from_pretrained(model_name)

def translate_to_en(text: str):
    if not isinstance(text, str) or text.strip() == "":
        return ""
    tokenizer.src_lang = "tr"
    encoded = tokenizer(text, return_tensors="pt", truncation=True, max_length=256)
    generated_tokens = model.generate(**encoded, forced_bos_token_id=tokenizer.get_lang_id("en"))
    return tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]

# ---------------------------------------------------------
# ğŸ”¹ VektÃ¶r veritabanÄ± oluÅŸturma
# ---------------------------------------------------------
def build_vector_db():
    """TÃ¼m ilanlardan embedding tabanÄ± oluÅŸturur (filtre yok)."""
    df = pd.read_csv("data/job_postings.csv")

    # Sadece gerekli sÃ¼tunlarÄ± al
    if "title" in df.columns and "description" in df.columns:
        df = df[["title", "description"]].dropna()
    else:
        raise ValueError(f"âš ï¸ Beklenen kolonlar bulunamadÄ±. Mevcut kolonlar: {df.columns.tolist()}")

    # Ä°lan metinlerini birleÅŸtir
    texts = [f"Title: {t}\nDescription: {d}" for t, d in zip(df["title"], df["description"])]

    # Embedding modeli
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

    # Chroma veritabanÄ±nÄ± oluÅŸtur
    db = Chroma.from_texts(texts, embedding=embeddings, persist_directory="./chroma_jobs")
    db.persist()

    print(f"âœ… {len(df)} ilan Chroma veritabanÄ±na kaydedildi.")
    return db


# ---------------------------------------------------------
# ğŸ”¹ CV KarÅŸÄ±laÅŸtÄ±rma (Gemini)
# ---------------------------------------------------------
def query_rag(cv_text, job_title=None):
    """KullanÄ±cÄ±nÄ±n CV'si ve (isteÄŸe baÄŸlÄ±) pozisyon baÅŸlÄ±ÄŸÄ±na gÃ¶re en alakalÄ± ilanlarÄ± bulur ve Gemini ile deÄŸerlendirir."""
    
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
    db = Chroma(persist_directory="./chroma_software_jobs", embedding_function=embeddings)

    # 1ï¸âƒ£ CV + baÅŸlÄ±ÄŸÄ± tek metin haline getir
    query_text = f"{job_title or ''} {cv_text}"

    # 2ï¸âƒ£ Bu metnin embedding'ini Ã§Ä±kar
    query_emb = embeddings.embed_query(query_text)

    # 3ï¸âƒ£ En benzer 5 ilanÄ± getir
    results = db.similarity_search_by_vector(query_emb, k=5)
    postings = "\n\n".join([r.page_content for r in results])

    # 4ï¸âƒ£ Gemini modeli
    model = genai.GenerativeModel("gemini-2.5-pro")

    prompt = f"""
AÅŸaÄŸÄ±da bir adayÄ±n Ã¶zgeÃ§miÅŸi (CV) ve benzer iÅŸ ilanlarÄ± verilmiÅŸtir.
Senin gÃ¶revin:
- AdayÄ±n becerilerini ve deneyimini deÄŸerlendir.
- Ä°lanlardaki gereksinimlerle karÅŸÄ±laÅŸtÄ±r.
- Genel uyum oranÄ±nÄ± tahmin et (0â€“100).
- TÃ¼rkÃ§e kÄ±sa bir Ã¶zet oluÅŸtur (gÃ¼Ã§lÃ¼ yÃ¶nler, geliÅŸtirmesi gerekenler).
- En uygun 3 pozisyonu Ã¶ner.

---
ğŸ§‘â€ğŸ’¼ CV + BaÅŸlÄ±k:
{cv_text}

ğŸ’¼ Benzer Ä°lanlar:
{postings}

---
CevabÄ±nÄ± tam JSON formatÄ±nda dÃ¶ndÃ¼r:
{{
  "match_percentage": <oran>,
  "summary_tr": "<tÃ¼rkÃ§e Ã¶zet>",
  "suggested_jobs": ["Pozisyon 1", "Pozisyon 2", "Pozisyon 3"]
}}
"""

    # 5ï¸âƒ£ Gemini'ye gÃ¶nder
    response = model.generate_content(prompt)

    try:
        text_output = (
            response.text
            if hasattr(response, "text")
            else response.candidates[0].content.parts[0].text
        )
        start = text_output.find("{")
        end = text_output.rfind("}") + 1
        json_str = text_output[start:end]
        data = json.loads(json_str)

    except Exception as e:
        print("âš ï¸ JSON ayrÄ±ÅŸtÄ±rma hatasÄ±:", e)
        print("ğŸ” Modelden gelen ham Ã§Ä±ktÄ±:", text_output if 'text_output' in locals() else str(response))
        data = {
            "match_percentage": 0,
            "summary_tr": "Model yanÄ±tÄ±nÄ± dÃ¼zgÃ¼n biÃ§imde Ã§Ã¶zemedi.",
            "suggested_jobs": []
        }

    data["match_percentage"] = max(0, min(float(data.get("match_percentage", 0)), 100))
    return data
